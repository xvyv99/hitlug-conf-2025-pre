
@misc{noauthor__2022,
	title = {编译器与中间表示: {LLVM} {IR}, {SPIR}-{V}, 以及 {MLIR}},
	shorttitle = {编译器与中间表示},
	url = {https://www.lei.chat/zh/posts/compilers-and-irs-llvm-ir-spirv-and-mlir/},
	abstract = {总体介绍编译器和中间表示 (LLVM IR, SPIR-V, and MLIR) 的发展历史和演进趋势},
	language = {zh},
	urldate = {2025-10-26},
	journal = {Lei.Chat()},
	month = jan,
	year = {2022},
	note = {Section: posts},
	file = {Snapshot:/Users/xvyv99/My_Data/Sync/Zotero/storage/FX9GATWL/compilers-and-irs-llvm-ir-spirv-and-mlir.html:text/html},
}

@inproceedings{lattner_mlir_2021,
	title = {{MLIR}: {Scaling} {Compiler} {Infrastructure} for {Domain} {Specific} {Computation}},
	shorttitle = {{MLIR}},
	url = {https://ieeexplore.ieee.org/abstract/document/9370308},
	doi = {10.1109/CGO51591.2021.9370308},
	abstract = {This work presents MLIR, a novel approach to building reusable and extensible compiler infrastructure. MLIR addresses software fragmentation, compilation for heterogeneous hardware, significantly reducing the cost of building domain specific compilers, and connecting existing compilers together. MLIR facilitates the design and implementation of code generators, translators and optimizers at different levels of abstraction and across application domains, hardware targets and execution environments. The contribution of this work includes (1) discussion of MLIR as a research artifact, built for extension and evolution, while identifying the challenges and opportunities posed by this novel design, semantics, optimization specification, system, and engineering. (2) evaluation of MLIR as a generalized infrastructure that reduces the cost of building compilers-describing diverse use-cases to show research and educational opportunities for future programming languages, compilers, execution environments, and computer architecture. The paper also presents the rationale for MLIR, its original design principles, structures and semantics.},
	urldate = {2025-10-26},
	booktitle = {2021 {IEEE}/{ACM} {International} {Symposium} on {Code} {Generation} and {Optimization} ({CGO})},
	author = {Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},
	month = feb,
	year = {2021},
	keywords = {Buildings, Generators, Hardware, Optimization, Program processors, Semantics, Software},
	pages = {2--14},
	file = {Full Text PDF:/Users/xvyv99/My_Data/Sync/Zotero/storage/BHE7D4HG/Lattner 等 - 2021 - MLIR Scaling Compiler Infrastructure for Domain Specific Computation.pdf:application/pdf},
}

@article{govindarajan_syfer-mlir_nodate,
	title = {{SyFER}-{MLIR}: {Integrating} {Fully} {Homomorphic} {Encryption} {Into} the {MLIR} {Compiler} {Framework}},
	abstract = {Fully homomorphic encryption opens up the possibility of secure computation on private data. However, fully homomorphic encryption is limited by its speed and the fact that arbitrary computations must be represented by combinations of primitive operations, such as addition, multiplication, and binary gates. Integrating FHE into the MLIR compiler infrastructure allows it to be automatically optimized at many different levels and will allow any program which compiles into MLIR to be modiﬁed to be encrypted by simply passing another ﬂag into the compiler. The process of compiling into an intermediate representation and dynamically generating the encrypted program, rather than calling functions from a library, also allows for optimizations across multiple operations, such as rewriting a DAG of operations to run faster and removing unnecessary operations.},
	language = {en},
	author = {Govindarajan, Sanath and Moses, William S},
	file = {PDF:/Users/xvyv99/My_Data/Sync/Zotero/storage/6N2HT5VD/Govindarajan和Moses - SyFER-MLIR Integrating Fully Homomorphic Encryption Into the MLIR Compiler Framework.pdf:application/pdf},
}

@misc{chen_tawa_2025,
	title = {Tawa: {Automatic} {Warp} {Specialization} for {Modern} {GPUs} with {Asynchronous} {References}},
	shorttitle = {Tawa},
	url = {http://arxiv.org/abs/2510.14719},
	doi = {10.48550/arXiv.2510.14719},
	abstract = {Modern GPUs feature specialized hardware units that enable high-performance, asynchronous dataflow execution. However, the conventional SIMT programming model is fundamentally misaligned with this task-parallel hardware, creating a significant programmability gap. While hardware-level warp specialization is the key to unlocking peak performance, it forces developers to manually orchestrate complex, low-level communication and software pipelines--a process that is labor-intensive, error-prone, and unsustainable. To address this challenge, we present Tawa, an automated compiler that systematically generates high-performance, warp-specialized code from a high-level, tile-based program. Central to our approach is a novel IR abstraction, asynchronous references (aref), which expresses warp-level communication without exposing low-level hardware details. Using this abstraction, Tawa automatically partitions programs into producer-consumer roles and manages the intricate dataflow pipeline, relieving developers of invasive kernel rewriting. Evaluation on NVIDIA H100 GPUs across representative LLM kernels shows that Tawa delivers high hardware utilization, achieving up to 1.1\${\textbackslash}times\$ speedup over highly optimized cuBLAS GEMM kernels. For attention workloads, Tawa attains 1.2\${\textbackslash}times\$ speedup over Triton and matches the performance of the hand-optimized CUTLASS C++ FlashAttention-3 kernel with far less programming effort.},
	urldate = {2025-10-26},
	publisher = {arXiv},
	author = {Chen, Hongzheng and Fan, Bin and Collins, Alexander and Hagedorn, Bastian and Gaburov, Evghenii and Masuda, Masahiro and Brookhart, Matthew and Sullivan, Chris and Knight, Jason and Zhang, Zhiru and Grover, Vinod},
	month = oct,
	year = {2025},
	note = {arXiv:2510.14719 [cs]},
	keywords = {Computer Science - Hardware Architecture, Computer Science - Machine Learning, Computer Science - Programming Languages},
	file = {Full Text PDF:/Users/xvyv99/My_Data/Sync/Zotero/storage/A3LJSY92/Chen 等 - 2025 - Tawa Automatic Warp Specialization for Modern GPUs with Asynchronous References.pdf:application/pdf;Snapshot:/Users/xvyv99/My_Data/Sync/Zotero/storage/BNBIHEM4/2510.html:text/html},
}
